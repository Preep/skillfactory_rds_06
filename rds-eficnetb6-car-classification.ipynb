{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import zipfile\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageOps, ImageFilter\n",
    "#увеличим дефолтный размер графиков\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "#графики в svg выглядят более четкими\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "%matplotlib inline\n",
    "\n",
    "print(os.listdir(\"../input\"))\n",
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)\n",
    "print('Tensorflow   :', tf.__version__)\n",
    "print('Keras        :', tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globar variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE           = 8 \n",
    "\n",
    "VAL_SPLIT            = 0.15\n",
    "\n",
    "CLASS_NUM            = 10\n",
    "IMG_SIZE             = 400\n",
    "IMG_CHANNELS         = 3\n",
    "input_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n",
    "\n",
    "DATA_PATH = '../input/'\n",
    "PATH = \"../working/car/\" # рабочая директория"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(PATH,exist_ok=False)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)  \n",
    "PYTHONHASHSEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic EDA and data unpacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH+\"train.csv\")\n",
    "sample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unpacking images')\n",
    "\n",
    "for data_zip in ['train.zip', 'test.zip']:\n",
    "    with zipfile.ZipFile(\"../input/\"+data_zip,\"r\") as z:\n",
    "        z.extractall(PATH)\n",
    "        \n",
    "print(os.listdir(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Image samples (random sample)')\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "random_image = train_df.sample(n=9)\n",
    "random_image_paths = random_image['Id'].values\n",
    "random_image_cat = random_image['Category'].values\n",
    "\n",
    "for index, path in enumerate(random_image_paths):\n",
    "    im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n",
    "    plt.subplot(3,3, index+1)\n",
    "    plt.imshow(im)\n",
    "    plt.title('Class: '+str(random_image_cat[index]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на примеры картинок и их размеры чтоб понимать как их лучше обработать и сжимать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = PIL.Image.open(PATH+'/train/0/100380.jpg')\n",
    "imgplot = plt.imshow(image)\n",
    "plt.show()\n",
    "image.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation and albumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/mjkvaak/ImageDataAugmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImageDataAugmentor.image_data_augmentor import *\n",
    "import albumentations\n",
    "\n",
    "    \n",
    "AUGMENTATIONS = albumentations.Compose([\n",
    "    albumentations.Transpose(p=0.1),\n",
    "    albumentations.Flip(p=0.1),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n",
    "        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n",
    "    ],p=0.5),\n",
    "    albumentations.GaussianBlur(p=0.05),\n",
    "    albumentations.HueSaturationValue(p=0.1),\n",
    "    albumentations.RGBShift(p=0.1),\n",
    "    albumentations.IAAPerspective(p=0.1),\n",
    "    albumentations.GridDistortion(p=0.5),    \n",
    "    albumentations.ShiftScaleRotate(p=0.2,\n",
    "                                    shift_limit=0.5,\n",
    "                                    scale_limit=0.5,\n",
    "                                    rotate_limit=40,\n",
    "    ),\n",
    "    albumentations.ElasticTransform(p=0.4,\n",
    "                                    alpha=0.1,\n",
    "                                    sigma=5,\n",
    "                                    alpha_affine=2,\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_datagen = ImageDataAugmentor(\n",
    "        rescale=1./255,\n",
    "        augment = AUGMENTATIONS,\n",
    "        augment_seed=RANDOM_SEED,\n",
    "        preprocess_input=None,\n",
    "        validation_split=VAL_SPLIT\n",
    ")\n",
    "        \n",
    "test_datagen = ImageDataAugmentor(\n",
    "        rescale=1./255\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        PATH+'train/',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=RANDOM_SEED,\n",
    "        subset='training')\n",
    "        \n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "        PATH+'train/',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=RANDOM_SEED,\n",
    "        subset='validation')\n",
    "\n",
    "test_sub_generator = test_datagen.flow_from_dataframe( \n",
    "        dataframe=sample_submission,\n",
    "        directory=PATH+'test_upload/',\n",
    "        x_col=\"Id\",\n",
    "        y_col=None,\n",
    "        shuffle=False,\n",
    "        class_mode=None,\n",
    "        seed=RANDOM_SEED,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet import tfkeras as efn\n",
    "\n",
    "base_model = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing a new head\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(CLASS_NUM, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best_model.hdf5',\n",
    "                             monitor = ['val_accuracy'] ,\n",
    "                             verbose = 1,\n",
    "                             mode = 'max')\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                            monitor = 'val_loss', \n",
    "                            factor = 0.5, \n",
    "                            patience = 3, \n",
    "                            min_lr=0.000001,\n",
    "                            verbose=1,\n",
    "                            mode='min') \n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "# https://towardsdatascience.com/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6\n",
    "# TODO: https://github.com/titu1994/keras-one-cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "LR = 0.001\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model.compile(\n",
    "              loss='categorical_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(learning_rate=LR) ,\n",
    "              metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = len(train_generator),\n",
    "        validation_data = test_generator, \n",
    "        validation_steps = len(test_generator),\n",
    "        epochs = EPOCHS,\n",
    "        callbacks = callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EPOCHS = 15\n",
    "\n",
    "\n",
    "base_model.trainable = True\n",
    "fine_tune_at = len(base_model.layers)//2\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False    \n",
    "print('Number of trainable layers in base model:', len(base_model.trainable_variables))\n",
    "\n",
    "model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=LR) ,\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = len(train_generator),\n",
    "        validation_data = test_generator, \n",
    "        validation_steps = len(test_generator),\n",
    "        epochs = EPOCHS,\n",
    "        callbacks = callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "EPOCHS = 3\n",
    "\n",
    "\n",
    "base_model.trainable = True\n",
    "fine_tune_at = len(base_model.layers)//4\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False    \n",
    "print('Number of trainable layers in base model:', len(base_model.trainable_variables))\n",
    "\n",
    "model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=LR) ,\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = len(train_generator),\n",
    "        validation_data = test_generator, \n",
    "        validation_steps = len(test_generator),\n",
    "        epochs = EPOCHS,\n",
    "        callbacks = callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "base_model.trainable = True\n",
    "\n",
    "\n",
    "model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=LR) ,\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = len(train_generator),\n",
    "        validation_data = test_generator, \n",
    "        validation_steps = len(test_generator),\n",
    "        epochs = EPOCHS,\n",
    "        callbacks = callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub_generator.reset()\n",
    "\n",
    "predictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1)\n",
    "# TTA result was somehow worse, so predicting on a simple generator\n",
    "\n",
    "predictions = np.argmax(predictions, axis=-1) #multiple categories\n",
    "label_map = (train_generator.class_indices)\n",
    "label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
    "predictions = [label_map[k] for k in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with_dir=test_sub_generator.filenames\n",
    "submission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\n",
    "submission['Id'] = submission['Id'].replace('test_upload/','')\n",
    "submission.to_csv('submission_v5.csv', index=False)\n",
    "print('Save submit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
